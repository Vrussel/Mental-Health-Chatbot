{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vrussel/Mental-Health-Chatbot/blob/main/Mental_Health_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmwdFtAJEg5w"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 759
        },
        "id": "8b2de6cf",
        "outputId": "2c52cb6a-f627-4402-caf9-7b581431b472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mental Health Chatbot (Type 'exit' or 'quit' to end)\n",
            "You: hello\n",
            "Sentiment detected: POSITIVE with score 1.00\n",
            "Mental Health Chatbot:  Hello there! It's wonderful to connect with you today.\n",
            "I am here to offer supportive information and general insights\n",
            "on various aspects of health and mental well-being.\n",
            "How can I assist you on your journey toward greater\n",
            "emotional balance and overall wellness? Feel free to share\n",
            "what's on your mind. We could explore stress management,\n",
            "mindfulness, building resilience, or ways to enhance your\n",
            "daily self-care routines. I'm ready to help.\n",
            "\n",
            "Disclaimer: This information is for general guidance only and does not replace professional advice. Consult a healthcare professional for personalized support.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3825140017.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    107\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mental Health Chatbot (Type 'exit' or 'quit' to end)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"exit\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"quit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "import re # Import regex for input filtering\n",
        "from transformers import pipeline # Import pipeline for sentiment analysis\n",
        "\n",
        "# Configure the Gemini API\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "# Initialize the Generative Model\n",
        "# You can choose a different model if needed\n",
        "gemini_model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "\n",
        "# Initialize sentiment analysis pipeline\n",
        "sentiment_analyzer = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "def mental_health_chatbot(prompt):\n",
        "  \"\"\"\n",
        "  Sends a prompt to the Gemini model and returns the response with ethical guardrails and sentiment analysis.\n",
        "  \"\"\"\n",
        "\n",
        "  # --- Sentiment Analysis ---\n",
        "  try:\n",
        "    sentiment = sentiment_analyzer(prompt)[0]\n",
        "    sentiment_label = sentiment['label']\n",
        "    sentiment_score = sentiment['score']\n",
        "    print(f\"Sentiment detected: {sentiment_label} with score {sentiment_score:.2f}\") # Optional: for debugging/monitoring\n",
        "  except Exception as e:\n",
        "    print(f\"Sentiment analysis failed: {e}\")\n",
        "    sentiment_label = \"neutral\" # Default to neutral if analysis fails\n",
        "\n",
        "\n",
        "  # --- Input Filtering (More Advanced) ---\n",
        "  # Combine keyword checking with sentiment for potentially better filtering\n",
        "  # This is a simplified example; more complex logic can be added\n",
        "  off_topic_keywords = [\"sports\", \"politics\", \"math\", \"calculate\", \"solve\", \"science\", \"history\", \"news\", \"entertainment\", \"technology\", \"finance\", \"legal\"]\n",
        "  if any(keyword in prompt.lower() for keyword in off_topic_keywords) and sentiment_label == \"neutral\":\n",
        "       return \"I'm sorry, I can only discuss topics related to health and mental well-being. For other questions, please consult a relevant professional or resource.\"\n",
        "\n",
        "  # Redirect severe prompts - keep this relatively strict\n",
        "  severe_keywords = [\"suicidal\", \"harm myself\", \"emergency\", \"crisis\", \"danger\", \"abuse\"]\n",
        "  if any(keyword in prompt.lower() for keyword in severe_keywords) or (sentiment_label == \"negative\" and sentiment_score > 0.9): # Consider strong negative sentiment as a trigger\n",
        "      return \"If you are experiencing a mental health crisis or feel in danger, please seek immediate help. You can contact a crisis hotline, emergency services, or a mental health professional in your area. I am not equipped to handle emergencies.\"\n",
        "\n",
        "  # Filter medical diagnosis/medication requests\n",
        "  medical_keywords = [\"medical diagnosis\", \"medication\", \"prescription\", \"diagnose\", \"cure\", \"treat\"]\n",
        "  if any(keyword in prompt.lower() for keyword in medical_keywords):\n",
        "      return \"I cannot provide medical diagnoses or recommend medication. Please consult a healthcare professional for personalized medical advice.\"\n",
        "\n",
        "  # Add helpline number for mental health issues\n",
        "  mental_health_keywords = [\"depressed\", \"anxious\", \"stress\", \"sad\", \"lonely\", \"struggling\", \"mental health\"]\n",
        "  helpline_number = \"National Crisis and Suicide Lifeline: 988\"\n",
        "  if any(keyword in prompt.lower() for keyword in mental_health_keywords) or sentiment_label in [\"negative\", \"very negative\"]:\n",
        "      helpline_message = f\"\\n\\nIf you are experiencing a mental health crisis, please reach out for help. You can contact the {helpline_number}.\"\n",
        "  else:\n",
        "      helpline_message = \"\"\n",
        "\n",
        "\n",
        "  # --- Ethical Directions to the LLM (via prompt engineering) ---\n",
        "  # Add instructions to the prompt to guide the model's behavior\n",
        "  # Include sentiment information in the prompt to potentially guide the response tone\n",
        "  ethical_prompt = f\"\"\"You are a helpful and supportive mental health chatbot providing general information and support related to health and mental well-being.\n",
        "  The user's input has been analyzed as having a {sentiment_label} sentiment.\n",
        "  Strictly adhere to the following guidelines:\n",
        "  - Your primary focus is to provide helpful and general information about mental health and well-being.\n",
        "  - Do not provide medical diagnoses, recommend medication, or advise on physical health issues.\n",
        "  - Do not generate content related to self-harm, harm to others, or illegal activities.\n",
        "  - If a query is severe (e.g., related to suicidal thoughts, crisis, or danger), immediately and strongly recommend seeking help from a qualified mental health professional, crisis hotline, or emergency services. Do not attempt to handle the crisis yourself.\n",
        "  - If a query is off-topic (not related to health or mental well-being), politely state that you can only discuss those topics and offer to help with a relevant question.\n",
        "  - Always prioritize providing accurate and general information within the scope of health and mental well-being.\n",
        "  - Be liberal in your interpretation of what is \"health or mental health related\" to be as helpful as possible within the safety guidelines.\n",
        "  - Respond in a tone appropriate to the detected sentiment, while remaining professional and supportive.\n",
        "  - Give a thorough response and suggest multiple solutions\n",
        "  ONLY WRITE 20 WORDS PER LINE\n",
        "\n",
        "  Respond to the following user input:\n",
        "\n",
        "  {prompt}\n",
        "  \"\"\"\n",
        "\n",
        "  try:\n",
        "    response = gemini_model.generate_content(ethical_prompt)\n",
        "    raw_response_text = response.text.strip()\n",
        "\n",
        "    # --- Advanced Output Safety ---\n",
        "    # Use regex or more complex pattern matching for sensitive topics if needed\n",
        "    # For now, continue with keyword checks and rely on prompt engineering\n",
        "    sensitive_keywords_output = [\"harm\", \"kill yourself\", \"suicide methods\", \"medication\", \"prescription\", \"diagnose\"]\n",
        "    if any(keyword in raw_response_text.lower() for keyword in sensitive_keywords_output):\n",
        "         return \"I cannot provide information related to harmful actions, medication, or diagnosis. If you are having thoughts of harming yourself, please seek immediate help from a professional or crisis service.\"\n",
        "\n",
        "\n",
        "    # Add disclaimers to all responses\n",
        "    disclaimer = \"\\n\\nDisclaimer: This information is for general guidance only and does not replace professional advice. Consult a healthcare professional for personalized support.\"\n",
        "\n",
        "    # Include a reminder for severe cases if the model's response didn't already strongly recommend it (as a fallback)\n",
        "    severe_reminder = \"\"\n",
        "    if any(keyword in prompt.lower() for keyword in severe_keywords) and not any(keyword in raw_response_text.lower() for keyword in [\"crisis hotline\", \"emergency services\", \"mental health professional\", \"seek help\"]):\n",
        "         severe_reminder = \"\\n\\nIf you are experiencing a mental health crisis, please seek immediate help from a professional or crisis service.\"\n",
        "\n",
        "\n",
        "    return raw_response_text + helpline_message + severe_reminder + disclaimer\n",
        "\n",
        "  except Exception as e:\n",
        "    return f\"An error occurred: {e}\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  print(\"Mental Health Chatbot (Type 'exit' or 'quit' to end)\")\n",
        "  while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == \"exit\" or user_input.lower() == \"quit\":\n",
        "      break\n",
        "    response = mental_health_chatbot(user_input)\n",
        "    print(\"Mental Health Chatbot: \", response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53c6f769"
      },
      "outputs": [],
      "source": [
        "for m in genai.list_models():\n",
        "  print(f\"{m.name}: {m.supported_generation_methods}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91be3ac3"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "print(\"Gemini API configured successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrtzPqu8QLCR",
        "outputId": "a2a62931-edb8-474c-9bca-1f233294c0df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwu2j+yUIAL/00EXRqg1qT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}